import argparse
import os
import torch
import torch.nn as nn
from model import ShaderMLP


def flatten_row_major(t: torch.Tensor) -> list[float]:
    # Expect weight shaped [out, in]; convert to row-major [out*in]
    return t.detach().cpu().float().contiguous().view(-1).tolist()


def pack_as_vec4(floats: list[float]) -> list[str]:
    """Pack floats into vec4 arrays. Returns vec4 array strings."""
    padded = floats[:]
    rem = len(padded) % 4
    if rem > 0:
        padded.extend([0.0] * (4 - rem))
    vec4s = []
    for i in range(0, len(padded), 4):
        vec4s.append(f'vec4({padded[i]:.4f},{padded[i+1]:.4f},{padded[i+2]:.4f},{padded[i+3]:.4f})')
    return vec4s


def export_to_glsl(model: ShaderMLP, out_path: str, var_prefix: str = 'SIREN', inline_scalars: bool = True) -> None:
    fmt = lambda v: f"{v:.4f}"
    parts: list[str] = []
    parts.append('// Auto-generated by export_glsl_shader.py')
    parts.append('// Full fragment shader with embedded weights (rounded to 4 decimals)')
    parts.append('')
    parts.append('// Uniforms expected: iTime, iResolution')
    parts.append(f'const float {var_prefix}_FIRST_OMEGA0 = {fmt(model.first_omega_0)};')
    parts.append(f'const float {var_prefix}_HIDDEN_OMEGA0 = {fmt(model.hidden_omega_0)};')
    parts.append(f'const float {var_prefix}_TMAX = {fmt(1.0)};')
    parts.append('')

    # First layer
    W0 = model.first_layer.linear.weight  # [H, in]
    b0 = model.first_layer.linear.bias
    H = W0.shape[0]
    IN = W0.shape[1]
    parts.append(f'const int {var_prefix}_IN = {IN};')
    parts.append(f'const int {var_prefix}_H = {H};')
    parts.append('')
    if not inline_scalars:
        w0_list = flatten_row_major(W0)
        b0_list = b0.detach().cpu().float().tolist()
        parts.append(f'const float {var_prefix}_W0[{H * IN}] = float[](')
        parts.append(','.join(fmt(v) for v in w0_list))
        parts.append(');')
        parts.append(f'const float {var_prefix}_B0[{H}] = float[](')
        parts.append(','.join(fmt(v) for v in b0_list))
        parts.append(');')
        parts.append('')
    else:
        import numpy as np
        W0_np = W0.detach().cpu().float().numpy()
        b0_np = b0.detach().cpu().float().numpy()
        W0_rows = W0_np.reshape(H, IN).tolist()
        b0_list = b0_np.reshape(H).tolist()

    # Hidden layers (H x H)
    L = len(model.hidden_layers)
    parts.append(f'const int {var_prefix}_L = {L};')
    hidden_rows: list[list[float]] = []
    hidden_biases: list[list[float]] = []
    if inline_scalars:
        for li, layer in enumerate(model.hidden_layers):
            W = layer.linear.weight.detach().cpu().float().numpy()
            b = layer.linear.bias.detach().cpu().float().numpy()
            hidden_rows.append(W.reshape(H, H).tolist())
            hidden_biases.append(b.reshape(H).tolist())
    else:
        for li, layer in enumerate(model.hidden_layers):
            W = layer.linear.weight
            b = layer.linear.bias
            wl = flatten_row_major(W)
            bl = b.detach().cpu().float().tolist()
            for r in range(H):
                row = wl[r * H:(r + 1) * H]
                parts.append(f'const float {var_prefix}_W{li+1}_R{r}[{H}] = float[](')
                parts.append(','.join(fmt(v) for v in row))
                parts.append(');')
            parts.append(f'const float {var_prefix}_B{li+1}[{H}] = float[](')
            parts.append(','.join(fmt(v) for v in bl))
            parts.append(');')
            parts.append('')

    # Head: find linear layers inside model.net (excludes Sine layers)
    head_linears = [m for m in model.net if isinstance(m, nn.Linear)]
    w_out = None
    b_out = None
    if len(head_linears) == 1:
        lin = head_linears[0]  # Linear(hidden, 1)
        w_out = flatten_row_major(lin.weight)
        b_out = lin.bias.detach().cpu().float().tolist() if lin.bias is not None else [0.0]
        if not inline_scalars:
            parts.append(f'const float {var_prefix}_W_OUT[{H}] = float[](')
            parts.append(','.join(fmt(v) for v in w_out))
            parts.append(');')
            parts.append(f'const float {var_prefix}_B_OUT[1] = float[]({fmt(b_out[0])});')
            parts.append('')
    elif len(head_linears) >= 2:
        lin1 = head_linears[0]  # Linear(hidden, hidden//2)
        lin2 = head_linears[1]  # Linear(hidden//2, 1)
        H2 = lin1.out_features
        parts.append(f'const int {var_prefix}_H2 = {H2};')
        w_head1 = flatten_row_major(lin1.weight)
        b_head1 = lin1.bias.detach().cpu().float().tolist()
        parts.append(f'const float {var_prefix}_W_HEAD1[{H * H2}] = float[](')
        parts.append(','.join(fmt(v) for v in w_head1))
        parts.append(');')
        parts.append(f'const float {var_prefix}_B_HEAD1[{H2}] = float[](')
        parts.append(','.join(fmt(v) for v in b_head1))
        parts.append(');')
        parts.append('')
        w_head2 = flatten_row_major(lin2.weight)
        b_head2 = lin2.bias.detach().cpu().float().tolist()
        parts.append(f'const float {var_prefix}_W_HEAD2[{H2}] = float[](')
        parts.append(','.join(fmt(v) for v in w_head2))
        parts.append(');')
        parts.append(f'const float {var_prefix}_B_HEAD2[1] = float[]({fmt(b_head2[0])});')
        parts.append('')
    else:
        raise RuntimeError('No Linear head found in model.net')

    parts.append('// Inference (globals only) and mainImage')
    parts.append('float sigmoid(float z) { return 1.0 / (1.0 + exp(-z)); }')
    parts.append('')
    parts.append('void mainImage(out vec4 fragColor, in vec2 fragCoord) {')
    parts.append('  // Aspect-correct normalized coords in [-1,1]')
    parts.append('  vec2 centered = fragCoord - 0.5 * iResolution.xy;')
    parts.append('  float s = min(iResolution.x, iResolution.y) * 0.5;')
    parts.append('  vec2 uv = centered / s;')
    parts.append(f'  float t = iTime / {var_prefix}_TMAX;')
    if inline_scalars:
        parts.append('  float x0 = uv.x; float x1 = uv.y; float x2 = t;')
        for r in range(H):
            row_vals = W0_rows[r]
            bval = b0_list[r]
            expr_terms = [f'{fmt(row_vals[j])}*x{j}' for j in range(IN)]
            sum_expr = ' + '.join(expr_terms) if expr_terms else '0.0'
            parts.append(f'  float h1_{r} = {sum_expr} + {fmt(bval)};')
        for r in range(H):
            parts.append(f'  float h1_{r} = sin({var_prefix}_FIRST_OMEGA0 * h1_{r});')
    else:
        parts.append(f'  float x0[{IN}];')
        parts.append('  x0[0] = uv.x; x0[1] = uv.y;')
        if IN >= 3:
            parts.append('  x0[2] = t;')
        parts.append(f'  float h1[{H}];')
        parts.append(f'  for (int r = 0; r < {H}; ++r) {{')
        parts.append(f'    float acc = 0.0;')
        parts.append(f'    int base = r * {IN};')
        parts.append(f'    for (int c = 0; c < {IN}; ++c) acc += {var_prefix}_W0[base + c] * x0[c];')
        parts.append(f'    h1[r] = acc + {var_prefix}_B0[r];')
        parts.append('  }')
        parts.append(f'  for (int i = 0; i < {H}; ++i) h1[i] = sin({var_prefix}_FIRST_OMEGA0 * h1[i]);')
    if L > 0 and not inline_scalars:
        parts.append(f'  float a[{H}]; for (int i = 0; i < {H}; ++i) a[i] = h1[i];')
        parts.append(f'  float tmp[{H}];')
        for li in range(L):
            for r in range(H):
                parts.append('  {')
                parts.append('    float acc = 0.0;')
                parts.append(f'    for (int c = 0; c < {H}; ++c) acc += {var_prefix}_W{li+1}_R{r}[c] * a[c];')
                parts.append(f'    tmp[{r}] = acc + {var_prefix}_B{li+1}[{r}];')
                parts.append('  }')
            parts.append(f'  for (int i = 0; i < {H}; ++i) a[i] = sin({var_prefix}_HIDDEN_OMEGA0 * tmp[i]);')
    elif L > 0 and inline_scalars:
        # Inline scalars: expand a0..a{H-1} and compute layer by layer fully unrolled
        # Seed a from h1
        for i in range(H):
            parts.append(f'  float a{i} = h1_{i};')
        for li in range(L):
            # tmp variables
            for r in range(H):
                # acc = sum_j W[r,j] * a_j + b[r]
                row_vals = hidden_rows[li][r]
                bval = hidden_biases[li][r]
                expr_terms = [f'{fmt(row_vals[j])}*a{j}' for j in range(H)]
                sum_expr = ' + '.join(expr_terms) if expr_terms else '0.0'
                parts.append(f'  float t{li}_{r} = {sum_expr} + {fmt(bval)};')
            # apply sine to produce next a
            for r in range(H):
                parts.append(f'  a{r} = sin({var_prefix}_HIDDEN_OMEGA0 * t{li}_{r});')
    else:
        parts.append(f'  float a[{H}]; for (int i = 0; i < {H}; ++i) a[i] = h1[i];')
    if len(head_linears) == 1 and not inline_scalars:
        parts.append('  float z = 0.0;')
        parts.append(f'  for (int c = 0; c < {H}; ++c) z += {var_prefix}_W_OUT[c] * a[c];')
        parts.append(f'  z += {var_prefix}_B_OUT[0];')
    elif len(head_linears) == 1 and inline_scalars:
        parts.append('  float z = 0.0;')
        for j in range(H):
            parts.append(f'  z += {fmt(w_out[j])} * a{j};')
        parts.append(f'  z += {fmt(b_out[0])};')
    else:
        parts.append(f'  float a2[{H2}];')
        parts.append(f'  for (int r = 0; r < {H2}; ++r) {{')
        parts.append('    float acc = 0.0;')
        parts.append(f'    int base = r * {H};')
        parts.append(f'    for (int c = 0; c < {H}; ++c) acc += {var_prefix}_W_HEAD1[base + c] * a[c];')
        parts.append(f'    a2[r] = acc + {var_prefix}_B_HEAD1[r];')
        parts.append('  }')
        parts.append('  float z = 0.0;')
        parts.append(f'  for (int c = 0; c < {H2}; ++c) z += {var_prefix}_W_HEAD2[c] * a2[c];')
        parts.append(f'  z += {var_prefix}_B_HEAD2[0];')
    parts.append('  float intensity = sigmoid(z);')
    parts.append('  fragColor = vec4(vec3(intensity), 1.0);')
    parts.append('}')

    glsl = '\n'.join(parts)
    with open(out_path, 'w') as f:
        f.write(glsl)


def count_uniform_floats(model: ShaderMLP) -> int:
    total = 0
    total += model.first_layer.linear.weight.numel() + model.first_layer.linear.bias.numel()
    for layer in model.hidden_layers:
        total += layer.linear.weight.numel() + layer.linear.bias.numel()
    head_linears = [m for m in model.net if isinstance(m, nn.Linear)]
    for lin in head_linears:
        total += lin.weight.numel() + (lin.bias is not None and lin.bias.numel() or 0)
    return int(total)


def main() -> None:
    parser = argparse.ArgumentParser(description='Export ShaderMLP weights as GLSL const arrays')
    parser.add_argument('--ckpt', type=str, default='.cache/models/best_model.pth')
    parser.add_argument('--out', type=str, default='.cache/frames/siren_weights.glsl')
    parser.add_argument('--var_prefix', type=str, default='SIREN')
    parser.add_argument('--device', type=str, default='cpu')
    parser.add_argument('--no-inline', action='store_true', dest='no_inline', help='Disable scalar inlining (use arrays)')
    # Always export all weights/biases; no limiting/warnings
    args = parser.parse_args()

    device = torch.device(args.device)
    model = ShaderMLP().to(device)
    ckpt = torch.load(args.ckpt, map_location=device)
    sd = ckpt.get('model_state_dict', ckpt)
    if any(k.startswith('_orig_mod.') for k in sd.keys()):
        sd = {k.replace('_orig_mod.', ''): v for k, v in sd.items()}
    model.load_state_dict(sd)
    model.eval()

    n_floats = count_uniform_floats(model)
    print(f'Uniform floats (weights + biases): {n_floats}')

    os.makedirs(os.path.dirname(args.out), exist_ok=True)
    export_to_glsl(model, args.out, var_prefix=args.var_prefix, inline_scalars=not args.no_inline)
    print(f'GLSL weights written to: {args.out}')


if __name__ == '__main__':
    main()


