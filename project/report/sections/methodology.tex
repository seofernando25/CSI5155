\section{Methodology}

The project is structured as a two-part experiment. First, a classical baseline is established using a Support Vector Machine with Fisher Vector features. Second, a model-wise double descent curve is experimentally induced by training a series of scalable Convolutional Neural Networks.

\subsection{Dataset and Preprocessing}

The CIFAR-10 dataset \cite{krizhevsky2009learning} is used, which consists of 60,000 32x32 color images across 10 classes. The standard 50,000 image training set and 10,000 image test set are used.

The data partitioning is as follows:

\begin{itemize}
    \item The 50,000 image training set is split into a 40,000 image training set and a 10,000 image validation set.
    \item The official 10,000 image test set is held out and used only once to generate the final, reportable results.
\end{itemize}

To amplify the double descent effect, as suggested by the literature \cite{nakkiran2019deep}, 20\% label noise is introduced to the 40,000 image training set. This is done by permanently replacing the true label for 8,000 randomly selected training images with a uniformly random incorrect label \cite{zhang2017understanding, nakkiran2019deep}. The validation and test sets remain "clean" with their original correct labels. All models are trained on this noisy training set and evaluated on the clean validation and test sets.

\subsection{Classical Baseline}

The classical baseline uses a Linear Support Vector Classifier (LinearSVC) trained on Fisher Vector (FV) representations. Patches of size $8 \times 8$ pixels are densely extracted with a stride of 4. Principal Component Analysis (PCA) with whitening is applied to reduce the patch descriptors to $D = 24$ dimensions, retaining approximately 96\% of the variance. A Gaussian Mixture Model (GMM) with $K = 64$ components is fitted to the PCA-reduced patches. The resulting Fisher Vector for each image is $2 \times D \times K = 3{,}072$-dimensional. The FVs are standardized and used to train a LinearSVC with $L_2$ regularization. The $C$ (cost) hyperparameter is tuned on the 10,000-image clean validation set.

\subsection{CNN Architecture}

To answer RQ2, a model-wise double descent curve is generated using a $\text{ScaledCNN}(k)$ architecture, where layer widths scale with a factor $k$. The architecture is visualized in \autoref{fig:scaledcnn}.

\begin{figure}[ht]
\centering
\begin{tikzpicture}[
    node distance=0.8cm,
    conv/.style={draw=black, align=center},
    norm/.style={ draw=black, align=center},
    act/.style={ draw=black, align=center},
    pool/.style={ draw=black, align=center},
    linear/.style={ draw=black, align=center},
    arrow/.style={->, thick, >=stealth},
]
    % Block 1
    \node[conv] (conv1) {Conv2d\\$3 \to 16k$\\kernel\_size=3\\padding=1};
    \node[norm, right=of conv1] (bn1) {BatchNorm};
    \node[act, right=of bn1] (relu1) {ReLU};
    \node[pool, right=of relu1] (pool1) {MaxPool};
    
    % Block 2
    \node[conv, below=1.5cm of conv1] (conv2) {Conv2d\\$16k \to 32k$\\kernel\_size=3\\padding=1};
    \node[norm, right=of conv2] (bn2) {BatchNorm};
    \node[act, right=of bn2] (relu2) {ReLU};
    \node[pool, right=of relu2] (pool2) {MaxPool};
    
    % Block 3
    \node[conv, below=1.5cm of conv2] (conv3) {Conv2d\\$32k \to 64k$\\kernel\_size=3\\padding=1};
    \node[norm, right=of conv3] (bn3) {BatchNorm};
    \node[act, right=of bn3] (relu3) {ReLU};
    \node[pool, right=of relu3] (pool3) {AdaptiveAvgPool};
    
    % Final layers
    \node[below=1.5cm of conv3, minimum width=1.2cm] (flat) {Flatten};
    \node[linear, right=of flat] (linear) {Linear\\$64k \to 10$};
    
    % Arrows within blocks
    \draw[arrow] (conv1) -- (bn1);
    \draw[arrow] (bn1) -- (relu1);
    \draw[arrow] (relu1) -- (pool1);
    
    \draw[arrow] (conv2) -- (bn2);
    \draw[arrow] (bn2) -- (relu2);
    \draw[arrow] (relu2) -- (pool2);
    
    \draw[arrow] (conv3) -- (bn3);
    \draw[arrow] (bn3) -- (relu3);
    \draw[arrow] (relu3) -- (pool3);
    
    \draw[arrow] (pool3) -- (flat);
    \draw[arrow] (flat) -- (linear);
    
    % Vertical connections between blocks
    \draw[arrow] (pool1) -- (conv2);
    \draw[arrow] (pool2) -- (conv3);
    
    % Input
    \node[left=0.5cm of conv1, align=center] (input) {Input\\$32 \times 32 \times 3$};
    \draw[arrow] (input) -- (conv1);
    
    % Output
    \node[right=0.5cm of linear, align=center] (output) {Output\\10 classes};
    \draw[arrow] (linear) -- (output);
\end{tikzpicture}
\caption{Architecture of $\text{ScaledCNN}(k)$.}
\label{fig:scaledcnn}
\end{figure}

\subsubsection{Training Configuration}

To isolate model capacity ($k$) as the only independent variable, all other training hyperparameters were fixed across all $k$ values. I adopted the standard experimental setup from the literature for replicating this phenomenon on CIFAR-10 with 20\% label noise \cite{nakkiran2019deep}. The following fixed hyperparameters were used for all $\text{ScaledCNN}(k)$ models:

\begin{table}[H]
    \centering
    \begin{tabular}{ll}
        \toprule
        Hyperparameter & Value \\
        \midrule
        Optimizer & Adam \\
        Learning Rate & $1 \times 10^{-4}$ (constant) \\
        Weight Decay & $0.0$ \\
        Epochs & 500 \\
        \bottomrule
    \end{tabular}
\end{table}

This recipe ensures all models have sufficient time to "memorize" the noisy training data, a prerequisite for observing the second descent \cite{nakkiran2019deep}.

\subsubsection{Training}

A series of models with varying $k \in \{1, 2, 4, 8, 16, 32, 64\}$ were trained from scratch on the 40,000-image noisy training set. Performance was tracked on the 10,000-image clean validation set.

\subsubsection{Data Collection}

The final models were evaluated on the 10,000-image clean test set. This data is used to plot Test Accuracy vs. Model Capacity, which is hypothesized to reveal the double descent curve.

\subsection{Analysis}

To conduct a thorough analysis, two methods are used:

\subsubsection{Statistical Significance}

A simple t-test is invalid for comparing two classifiers on the same test set. Instead, the non-parametric McNemar's Test is used \cite{demsar2006statistical} to determine if observed performance differences are statistically significant ($p < 0.05$).

\subsubsection{Error Analysis}

A full $10\times10$ confusion matrix is generated for three key models: the classical SVM baseline, the critically-parameterized $\text{ScaledCNN}(k=4)$, and the over-parametrized $\text{ScaledCNN}(k=64)$. These matrices are qualitatively analyzed to identify patterns in inter-class confusions.
